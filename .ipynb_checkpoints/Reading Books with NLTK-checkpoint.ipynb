{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook on the Bible\n",
    "This is a Jupyter Notebook project for performing analysis on the bible.\n",
    "There are several translations of the bible. The translations that I am using\n",
    "for this project is RSV, NAB, DR and LV.\n",
    "\n",
    "I am using Apache Spark and Pandas frameworks. In addition, I am using the Natural Language Took Kit software package located here: `https://nltk.org`\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import nltk, re, pprint\n",
    "import nltk.data\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pandas\n",
    "import pydoop.hdfs as hdfs\n",
    "from nltk import word_tokenize\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Spark runtime\n",
    "Getting two important handles.\n",
    "\n",
    "- Get SparkSession\n",
    "- Get SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Reading the Bible').getOrCreate()\n",
    "sc    = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common functions for extracting the content of the bible\n",
    "Note that the bible is stored by translations. There are four (4) translation\n",
    "this project is using: \n",
    "\n",
    "- Douay-Rheims (DR)\n",
    "- Revised Standard Version (RSV)\n",
    "- Latin Vulgate (LV)\n",
    "- New American Bible (NAB)\n",
    "\n",
    "These are stored on sepearate directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants related to the Bible\n",
    "\n",
    "hdfs_dir        = '/user/thebible/'\n",
    "tmp_dir         = '/tmp/'\n",
    "rsv_translation = 'rsv'\n",
    "dr_translation  = 'dr'\n",
    "nab_translation = 'nab'\n",
    "lv_translation  = 'lv'\n",
    "filename_suffix = '-text.txt'\n",
    "translations    = [dr_translation, rsv_translation, lv_translation, nab_translation]\n",
    "\n",
    "column_translation_name = 'Translation'\n",
    "column_book_name        = 'Book Name'\n",
    "column_chapter_name     = 'Chapter'\n",
    "column_verse_name       = 'Verse'\n",
    "column_text_name        = 'Text'\n",
    "verse_column_names      = [column_translation_name, column_book_name, \\\n",
    "                           column_chapter_name, column_verse_name, \\\n",
    "                           column_text_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fully-qualified filename for a given book for a translation (dr, rsv, nab, lv)\n",
    "def get_fq_filename(base_dir, translation, book_filename):\n",
    "    return f'{base_dir}{translation}/{book_filename}'\n",
    "\n",
    "\n",
    "def get_csv_filename(dir_name, translation):\n",
    "    return f'{dir_name}{translation}.csv'\n",
    "\n",
    "def get_json_filename(dir_name, translation):\n",
    "    return f'{dir_name}{translation}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return an RDD of strings.\n",
    "\"\"\"\n",
    "https://spark.apache.org/docs/2.1.0/api/python/pyspark.html#pyspark.RDD:\n",
    "\n",
    "A Resilient Distributed Dataset (RDD), the basic abstraction in Spark. \n",
    "Represents an immutable, partitioned collection of elements \n",
    "that can be operated on in parallel.\n",
    "\"\"\"\n",
    "def read_file(filename):\n",
    "    return sc.textFile(filename)\n",
    "              \n",
    "def chapters_verses(rdd):\n",
    "    return rdd.filter(lambda line: line and not line.startswith('*** the book'))\n",
    "\n",
    "\"\"\"\n",
    "Get a list of file names for the books based on a given translation\n",
    "\"\"\"\n",
    "def get_filenames_for_books(base_dir, translation):\n",
    "    translation_dir = f'{base_dir}/{translation}/*{filename_suffix}'\n",
    "    buf = ''\n",
    "    file_names = []\n",
    "    with subprocess.Popen([\"hdfs\", \"dfs\", \"-ls\", translation_dir], stdout=subprocess.PIPE) as proc:\n",
    "        buf += re.sub('\\t', '', str(proc.stdout.read()))\n",
    "    for line in buf.split('\\\\n'):\n",
    "        tokens = []\n",
    "        for token in line.split(' '):\n",
    "            if token.strip() != '':\n",
    "                tokens.append(token)\n",
    "        if len(tokens) < 8:\n",
    "            continue\n",
    "        tokens = tokens[7].split('/')\n",
    "        file_names.append(tokens[len(tokens) - 1])\n",
    "    return file_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation | book_name | chapter_no | verse_no | text|\n",
    "\n",
    "\"\"\"\n",
    "for a given translation and a book name, read the content and \n",
    "extract only the actual content of the text for the book. Each\n",
    "verse is then organized as a row that contains: translation,\n",
    "name of the book, chapter number, verse number and the text of \n",
    "the verse. The row or the verse is added to a given array\n",
    "called 'verses'.\n",
    "\"\"\"\n",
    "def load_book(verses, translation, base_dir, book_filename):\n",
    "    rdd  = read_file(get_fq_filename(base_dir, translation, book_filename))\n",
    "    # skip until *** is found.\n",
    "    \n",
    "    cv_rdd = chapters_verses(rdd)\n",
    "    book_name = book_filename.replace(filename_suffix, '')\n",
    "\n",
    "    chapter_no = 0\n",
    "    verse_no = 0\n",
    "    \n",
    "    for line in cv_rdd.collect():\n",
    "        if line.startswith('***'):\n",
    "            chapter_no += 1\n",
    "            verse_no = 0\n",
    "        else:\n",
    "            if line[0].isdigit():\n",
    "                verse_no += 1\n",
    "                verses.append([translation, book_name, chapter_no, verse_no, line[line.find(' ')+1:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the entire bible by translation\n",
    "def load_the_bible(base_dir, translation):\n",
    "    filenames = get_filenames_for_books(base_dir, translation)\n",
    "    verses = []\n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "        load_book(verses, translation, base_dir, filename)\n",
    "\n",
    "    pd = spark.createDataFrame(verses).toPandas()\n",
    "    pd.columns = verse_column_names\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the info from the wc program\n",
    "def print_wc (filename):\n",
    "    with subprocess.Popen([\"wc\", filename], stdout=subprocess.PIPE) as proc:\n",
    "        content = str(proc.stdout.read()).replace('b\\'', '')\\\n",
    "                                         .strip()\\\n",
    "                                         .replace('\\\\n\\'', '')\\\n",
    "                                         .replace('\\t','')\n",
    "    # Removing extra spaces between words ... then split by space    \n",
    "    content = re.sub(' +', ' ', content).split(' ')\n",
    "    print(f'file: {content[3]}')\n",
    "    print(f'  {content[0]} lines')\n",
    "    print(f'  {content[1]} words')\n",
    "    print(f'  {content[2]} chateracters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bible from a csv file into a pandas dataframe\n",
    "\n",
    "def load_csv_into_pandas(dir_name, translation):\n",
    "    the_bible_filename = f'{dir_name}/{translation}.csv'\n",
    "    with hdfs.open(the_bible_filename) as reader:\n",
    "        pd_bible = pandas.read_csv(reader)\n",
    "        \n",
    "    return pd_bible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a pandas dataframe into a dictionary of book names.\n",
    "# Each book is a dictionary of chapter numbers.\n",
    "# Each chapter is a dictionary of verse numbers.\n",
    "# Each verse number contains the text of the verse.\n",
    "\n",
    "def pandas_as_dictionary(pd_bible):\n",
    "    the_bible = {}\n",
    "    for index, verse in pd_bible.iterrows():\n",
    "        book_name = verse[column_book_name]\n",
    "        chapter_no = verse[column_chapter_name]\n",
    "        verse_no = verse[column_verse_name]\n",
    "        verse_text = verse[column_text_name]\n",
    "        if book_name not in the_bible:\n",
    "            the_bible[book_name] = {}\n",
    "        if chapter_no not in the_bible[book_name]:\n",
    "            the_bible[book_name][chapter_no] = {}\n",
    "        the_bible[book_name][chapter_no][verse_no] = verse_text\n",
    "    \n",
    "    return the_bible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting csv file into a json file.\n",
    "def convert_csv_to_json(hdfs_dir, local_dir, translation):\n",
    "    pd_bible = load_csv_into_pandas(hdfs_dir, translation)\n",
    "    the_bible = pandas_as_dictionary(pd_bible)\n",
    "    the_bible_in_json = json.dumps(the_bible, indent=4)\n",
    "    with open(get_json_filename(local_dir, translation), 'w') as writer:\n",
    "        writer.write(the_bible_in_json)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running scenarios ...\n",
    "- Try out a couple of translation individually to make sure the code\n",
    "is working coorectly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name       = '01-Genesis'\n",
    "book_filename   = f'{book_name}{filename_suffix}'\n",
    "\n",
    "# Fully-Qualified filenames:\n",
    "dr_book_fq_filename  = f'{hdfs_dir}/{dr_translation}/{book_filename}'\n",
    "rsv_book_fq_filename = f'{hdfs_dir}/{rsv_translation}/{book_filename}'\n",
    "print(f'fully-qualified book file name: {dr_book_fq_filename}')\n",
    "print(f'fully-qualified book file name: {rsv_book_fq_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading books.\n",
    "The bible has many translation. The translations I am using for the analytics\n",
    "is based on the content I extract from the Internet. \n",
    "\n",
    "The bible is organized into books and stored in text files. The name of each\n",
    "file is in this format: `{book-name}-text.txt`. The `{book-name}` starts with\n",
    "a number from `01` to `73` and follows this format: `{book-number}-name`. For example,\n",
    "the book of `Genesis` would be `01-Genesis`. The book of `Revelation` is named\n",
    "as `73-Revelation`. The file name for the book of `Genesis` would be \n",
    "`01-Geneisis-text.txt` and for the book of `Revelation` `73-Revelation-text.txt`\n",
    "\n",
    "The content of each book follows this format:\n",
    "\n",
    "line 1: `*** the book of {book-name}`. The book-name is the actual name of the book. \n",
    "For example, `Genesis` or `Revelation`. There is no leading number as indicated\n",
    "above in the file name.\n",
    "\n",
    "line 2: empty\n",
    "\n",
    "line 3: `*** {book-name} {chapter-no}`. This is true for RSV, NAB and LV. For the \n",
    "case of DR, `Chapter ` is in place of the `{book-name}`.\n",
    "\n",
    "line 4: empty\n",
    "\n",
    "line 5: first verse of the first chapter of the book. The verse is stored in a \n",
    "`single` line of text leading by verse number starting from 1.\n",
    "\n",
    "... \n",
    "\n",
    "Each subsequent chapter follows the same format as that of the first chapter \n",
    "indicated above starting at line through line 5.\n",
    "\n",
    "### Example:\n",
    "\n",
    "\n",
    "```\n",
    "*** the book of Genesis\n",
    "\n",
    "*** Genesis 1 ***\n",
    "\n",
    "1 In the beginning God created the heavens and the earth.\n",
    "2 The earth was without form and void, and darkness was upon the face of the deep; and the Spirit of God was moving over the face of the waters.\n",
    "```\n",
    "....\n",
    "\n",
    "```\n",
    "31 And God saw everything that he had made, and behold, it was very good. And there was evening and there was morning, a sixth day.\n",
    "\n",
    "*** Genesis 2 ***\n",
    "\n",
    "1 Thus the heavens and the earth were finished, and all the host of them.\n",
    "2 And on the seventh day God finished his work which he had done, and he rested on the seventh day from all his work which he had done.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the array that contains all the verses.\n",
    "\n",
    "verses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading first book for 'DR' translation\n",
    "\n",
    "book_name       = '01-Genesis'\n",
    "book_filename   = f'{book_name}{filename_suffix}'\n",
    "load_book(verses, dr_translation, hdfs_dir, book_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Pandas data frame from the array of verses.\n",
    "pd_df = spark.createDataFrame(verses).toPandas()\n",
    "pd_df.columns = verse_column_names\n",
    "\n",
    "# Display pandas dataframe on screen ...\n",
    "pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the second book ...\n",
    "\n",
    "book_name       = '02-Exodus'\n",
    "book_filename   = f'{book_name}{filename_suffix}'\n",
    "load_book(verses, dr_translation, hdfs_dir, book_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Pandas data frame from the array of verses.\n",
    "pd_df = spark.createDataFrame(verses).toPandas()\n",
    "pd_df.columns = verse_column_names\n",
    "\n",
    "# Display pandas dataframe on screen ...\n",
    "pd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Pandas data frame into CSV file:\n",
    "We are converting a pandas dataframe that is a set of `Row's` int a \n",
    "CSV file. The CSV file has a header defined in the array of strings\n",
    "`verse_column_names`. Initially it would be this:\n",
    "\n",
    "```python\n",
    "column_translation_name = 'Translation'\n",
    "column_book_name        = 'Book Name'\n",
    "column_chapter_name     = 'Chapter'\n",
    "column_verse_name       = 'Verse'\n",
    "column_text_name        = 'Text'\n",
    "verse_column_names      = [column_translation_name, column_book_name, \\\n",
    "                           column_chapter_name, column_verse_name, \\\n",
    "                           column_text_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to store the content in a temporary folder in csv format.\n",
    "dr_csv_filename = get_csv_filename(tmp_dir, dr_translation)\n",
    "pd_df.to_csv(dr_csv_filename, index=False)\n",
    "print_wc(dr_csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire DR bible\n",
    "pd_dr = load_the_bible(hdfs_dir, dr_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to store the content in a temporary folder in csv format.\n",
    "dr_csv_filename = get_csv_filename(tmp_dir, dr_translation)\n",
    "pd_dr.to_csv(dr_csv_filename, index=False)\n",
    "print_wc(dr_csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RSV bible\n",
    "pd_rsv = load_the_bible(hdfs_dir, rsv_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to store the content in a temporary folder in csv format.\n",
    "rsv_csv_filename = get_csv_filename(tmp_dir, rsv_translation)\n",
    "pd_rsv.to_csv(rsv_csv_filename, index=False)\n",
    "print_wc(rsv_csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_rsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the four translations of the bible\n",
    "for translation in translations:\n",
    "    print(f'loading {translation} ...')\n",
    "    pd = load_the_bible(hdfs_dir, translation)\n",
    "    pd.to_csv(get_csv_filename(tmp_dir, translation), index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_array = []\n",
    "for translation in translations:\n",
    "    filename = get_csv_filename(tmp_dir, translation)\n",
    "    with subprocess.Popen([\"wc\", filename], stdout=subprocess.PIPE) as proc:\n",
    "        file_info = str(proc.stdout.read()).replace('b\\'', '')\\\n",
    "                                           .strip()\\\n",
    "                                           .replace('\\\\n\\'', '')\\\n",
    "                                           .replace('\\t','')\n",
    "    # Removing extra spaces between words ... then split by space    \n",
    "    file_info = re.sub(' +', ' ', file_info).split(' ')\n",
    "    info_array.append(file_info)\n",
    "\n",
    "pd_info = spark.createDataFrame(info_array).toPandas()\n",
    "pd_info.columns = ['Lines', 'Words', 'Characters', 'File Name']\n",
    "pd_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the bible of a given translation from a file.\n",
    "For each translation, we stored the entire bible on a CSV file\n",
    "where each row is a verse in a book. The row consists of \n",
    "the name of the translation (csv, lv, dr, nab), \n",
    "the name of the book (73 books in total), the chapter\n",
    "number, the verse number and the actual text of the verse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_rsv = load_csv_into_pandas(hdfs_dir, rsv_translation)\n",
    "pd_rsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsv_books = pd_rsv.groupby([column_book_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsv_chapters = pd_rsv.groupby([column_book_name, column_chapter_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsv_books.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsv_chapters.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing bible by books.\n",
    "the_bible is a dictionary of book names. Each book\n",
    "is an array of chapters. Since array is indexing at zero (0)\n",
    "and the chapters are numbered from 1, let's try \n",
    "to starting at 1. but that leave us an extra slot at zero (0)\n",
    "and causes a bit complication in counting that is to remember\n",
    "to substract 1. This is too messy.\n",
    "\n",
    "Let's uses dictionary all the way.\n",
    "the_bible is a dictionary by book name. Each book is a\n",
    "dictionary of chapters (starting 1). Each chapter is \n",
    "a dictionary of verses (starting 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_bible = pandas_as_dictionary(pd_rsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_bible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_bible['01-Genesis'][1][1], the_bible['73-Revelation'][22][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(the_bible), len(the_bible['01-Genesis']), len(the_bible['73-Revelation'][22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_bible_in_json = json.dumps(the_bible, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rsv.json', 'w') as writer:\n",
    "    writer.write(the_bible_in_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting the content of the bible from csv format to json format\n",
    "for translation in translations:\n",
    "    print(f'converting from csv to json for the translation: {translation} ...')\n",
    "    convert_csv_to_json(hdfs_dir, tmp_dir, translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starts Natural Language Took Kit here ...\n",
    "In this section, we are download the punkt and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download nltk modules.\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "detector = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "In this section, we assume that the_bible object is a dictionary of books of dictionary \n",
    "of chapters of dictionary of verses. \n",
    "For each book, we would like to know:\n",
    "\n",
    "- number of chapters\n",
    "- number of verses\n",
    "- number of sentences\n",
    "- number of words\n",
    "- number of words without stopwords (i.e., 'the', 'an', 'a', etc.)\n",
    "- number of unique words without stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_text(the_bible, the_book_name):\n",
    "    the_book_text = []\n",
    "    the_book = the_bible[the_book_name]\n",
    "\n",
    "    for chapter in the_book:\n",
    "        for verse in the_book[chapter]:\n",
    "            the_book_text.append(the_book[chapter][verse])\n",
    "\n",
    "    return the_book_text           \n",
    "\n",
    "the_book_name = '01-Genesis'\n",
    "the_book_text = get_book_text(the_bible, the_book_name)\n",
    "the_book_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all verses into a long string of text for the current book.\n",
    "the_book_tokens = word_tokenize(' '.join(the_book_text))\n",
    "len(the_book_tokens), the_book_tokens[43545]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = detector.tokenize(' '.join(the_book_text).strip())\n",
    "print(f'{the_book_name} has {len(sentences)} sentences')\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RSV bible\n",
    "pd_rsv = load_the_bible(hdfs_dir, rsv_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the bible into a long string\n",
    "the_text = ''\n",
    "for index, row in pd_rsv.iterrows():\n",
    "    the_text += ' ' + row ['Text']\n",
    "\n",
    "the_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the string\n",
    "the_tokens = word_tokenize(the_text)\n",
    "the_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting tokens into NLTK Text object\n",
    "nltk_text = nltk.Text(the_tokens)\n",
    "nltk_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a few things with nltk_text.\n",
    "\n",
    "nltk_text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_text.concordance('Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_text.concordance('Jesus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vip = ['God', 'Jesus', 'Adam', 'Eve', 'Abraham', 'Moses', 'Saul', 'David', 'Joseph', 'Mary', 'Peter', 'Paul', 'John']\n",
    "mention = []\n",
    "for person in vip:\n",
    "    mention.append([person, nltk_text.count(person)])\n",
    "    \n",
    "pd_mention = spark.createDataFrame(mention).toPandas()\n",
    "pd_mention.columns = ['Person', 'Mentioned']\n",
    "pd_mention\n",
    "# nltk_text.count('Jesus'), nltk_text.count('Adam'), nltk_text.count('Saul'), \\\n",
    "# nltk_text.count('David'), nltk_text.count('Joseph'), nltk_text.count('Mary'), \\\n",
    "# nltk_text.count('John')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch notebook starts here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsv_df = load_book(rsv_translation, book_name)\n",
    "rsv_df.groupby([column_chapter_name])[column_verse_name].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nab_df = load_book(nab_translation, book_name)\n",
    "nab_df.groupby([column_chapter_name])[column_verse_name].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_df = load_book(lv_translation, book_name)\n",
    "lv_df.groupby([column_chapter_name])[column_verse_name].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_df.count(), rsv_df.count(), nab_df.count(), lv_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "filter out metadata:  Like the following text:\n",
    "\n",
    "*** the book of Genesis\n",
    "\n",
    "*** Genesis 1 ***\n",
    "\n",
    "1 In the beginning God created the heavens and the earth.\n",
    "\n",
    "The first two lines should be excluded. The heading number of each \n",
    "line indicating the verse number should also be excluded.\n",
    "\n",
    "Use only line that starts with a digit in the first character.\n",
    "\"\"\"\n",
    "def verses_only(raw):\n",
    "    return raw.filter(lambda line: line and line[0].isdigit())\n",
    "\n",
    "\"\"\"\n",
    "Remove the verse number on each line.\n",
    "\"\"\"\n",
    "def words_only(verses):\n",
    "    return verses.map(lambda line: str(line[line.find(' ')+1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading contents from files.\n",
    "dr_rdd  = read_file(dr_book_filename)\n",
    "rsv_rdd  = read_file(rsv_book_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book_name | chapter_no | verse_no | text|\n",
    "# skip until *** is found.\n",
    "\n",
    "dr_cv_rdd = chapters_verses(dr_rdd)\n",
    "\n",
    "verses = []\n",
    "chapter_no = 0\n",
    "verse_no = 0\n",
    "for line in dr_cv_rdd.collect():\n",
    "    if line.startswith('***'):\n",
    "        chapter_no += 1\n",
    "        verse_no = 0\n",
    "    else:\n",
    "        if line[0].isdigit():\n",
    "            verse_no += 1\n",
    "            verses.append([book_name, chapter_no, verse_no, line[line.find(' ')+1:]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dr_df = spark.createDataFrame(verses)\n",
    "pd_df.columns = ['Book Name', 'Chapter', 'Verse', 'Text', 'Words', 'Sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract verses only (include verse # in the begining of each line). Eac line is a verse.\n",
    "dr_verses = verses_only(dr_rdd)\n",
    "rsv_verses = verses_only(rsv_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_verses.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract words only (eclude the # in the begining of each line)\n",
    "dr_words_only = words_only(dr_verses)\n",
    "rsv_words_only = words_only(rsv_verses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'There are {len(dr_words_only.collect())}/{len(rsv_words_only.collect())} verses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dr_words_only.collect()), len(rsv_words_only.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the entire book into a string of words ... Then tokenize it using NLTK.\n",
    "dr_words = '\\n'.join(word for word in list(dr_words_only.collect()))\n",
    "rsv_words = '\\n'.join(word for word in list(rsv_words_only.collect()))\n",
    "\n",
    "dr_tokens = word_tokenize(dr_words)\n",
    "rsv_tokens = word_tokenize(rsv_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making into NLTK objects for processing.\n",
    "dr_text = nltk.Text(dr_tokens)\n",
    "rsv_text = nltk.Text(rsv_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dr_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dr_text), len(rsv_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find in string returns # instances of all the substrings\n",
    "dr_words.find('Eve'), rsv_words.find('Eve'), dr_words.find('heaven'), rsv_words.find('heaven')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_text.count('Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_text.count('Eve'), dr_text.count('heaven')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_text.similar('living')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_text.common_contexts('cattle', 'of')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_text.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(dr_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set is a list of vocabulary items (unique words). \n",
    "# How many unique/distinct words in this book?\n",
    "len(set(dr_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collocation is a sequence of words that occur together unusually often.\n",
    "dr_text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concordance permits us to see words in context\n",
    "dr_text.concordance('Eve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigrams is a list of word pairs.\n",
    "len(list(nltk.bigrams(dr_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(dr_text)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_text.count('created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dr_text) / len(set(dr_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * dr_text.count('Joseph')/len(dr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_text.index('Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = set(dr_text)\n",
    "long_words = [w for w in V if len(w) > 10]\n",
    "sorted(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
